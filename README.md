# Local LLM (lllm)

A series of experiments with local LLMs

# TODOs

- [x] Run mistral 7b locally
- [x] Run llama 2 locally
- [x] Run custom prompts with llama 2
- [x] Run API calls against llama/mistral
