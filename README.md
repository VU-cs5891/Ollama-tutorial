# Local LLM (lllm)

A series of experiments with local LLMs

# TODOs

## Exp (Using Ollama)

- [x] Run mistral 7b locally
- [x] Run llama 2 locally
- [x] Run custom prompts with llama 2
- [x] Run API calls against llama/mistral

## Exp (Using Ollama for a Chat UI)

- [x] Create chat UI similar to [this](https://www.youtube.com/watch?v=n9AMtXLveMs)

## Exp (Use langchain to build something)

- [ ] Replicate [this](https://www.anaconda.com/blog/how-to-build-ai-chatbots-with-mistral-and-llama2)

## Exp (Train Mistral on your own data - finetuning)

## Exp (Get Twinny to work in VSCode)
